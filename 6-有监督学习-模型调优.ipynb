{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，经常会遇到两种问题，其一为过拟合，其一为欠拟合。\n",
    "\n",
    "- 过拟合是由于模型过于复杂，更倾向于对数据进行记忆，这样的模型泛化能力很差，对于这类错误被称作Error due to Variance；\n",
    "\n",
    "- 欠拟合是由于模型过于简单，不能对数据进行很好的预测。这类错误也被称作Error due to Bias。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那我们该如何更直观的评判出，模型是否处于过拟合或者欠拟合状态呢？\n",
    "### 模型复杂度曲线（Model Complexity Graph）\n",
    "\n",
    "我们可以用横轴表示模型的复杂度，用纵轴表示模型的Error，分别绘制训练集与验证集（**不是测试集哦！！**）的效果，如下图所示，显然模型在中间位置是处于最佳状态。\n",
    "\n",
    "![aybaE8.md.png](https://s1.ax1x.com/2020/08/05/aybaE8.md.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K折交叉验证\n",
    "\n",
    "为了获取更好的（泛化能力更强）模型，我们可以对数据进行分组，用数据的几部分作为训练集，剩余部分作为验证集，这样我们就可以获得一个K组数据用于模型拟合。\n",
    "\n",
    "如下图所示：\n",
    "![ayqsiD.md.png](https://s1.ax1x.com/2020/08/05/ayqsiD.md.png)\n",
    "\n",
    "这可以通过Sklearn来实现：\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(12,3)\n",
    "# 当然你还可以设定为随机取数\n",
    "kf = KFold(12,3,shuffle=True)\n",
    "\n",
    "for train_indices,val_indices in kf:\n",
    "    print(train_indices,val_indices)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习曲线（Learning Curve）\n",
    "\n",
    "我们还可以使用学习曲线来评判模型的拟合状态，曲线的绘制过程是这样的：\n",
    "- 选择n条样本对模型进行训练，记录模型对训练集与验证集的Error；\n",
    "- 不断增大n，并重复如上操作；\n",
    "- 将所有的结果绘制曲线。\n",
    "\n",
    "如下图，分别表示欠拟合（High Bias），最佳拟合与过拟合（High Variance）的学习曲线。\n",
    "\n",
    "![ayXPq1.md.png](https://s1.ax1x.com/2020/08/05/ayXPq1.md.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 欠拟合：两条曲线会不断靠近，但是最终会收敛在一个较高的Error；\n",
    "- 过拟合：两条曲线不断靠近，但二者平稳后，仍有一段距离，而且验证集的错误会收敛于较高的Error。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 表格搜索（Grid Search）\n",
    "\n",
    "在对模型进行优化时，往往需要调整多个超参数，我们可以根据这些超参数去绘制表格，然后逐个去验证各组超参数的模型性能，这种方法即为表格搜索。\n",
    "\n",
    "如下图所示，为SVM的两个超参数使用表格搜索寻找最优解的结果：\n",
    "![ayjBXd.png](https://s1.ax1x.com/2020/08/05/ayjBXd.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Sklearn中，可以按照如下方式调用GridSearch：\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 定义参数区间\n",
    "parameters = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "# 定义评分\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Create the object.\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "# Fit the data\n",
    "grid_fit = grid_obj.fit(X, y)\n",
    "\n",
    "# 获得最优结果\n",
    "best_clf = grid_fit.best_estimator_\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
