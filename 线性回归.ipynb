{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "### 如何拟合\n",
    "#### 两种技巧\n",
    "- 绝对值技巧（absolute trick）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![M0tMrj.md.png](https://s2.ax1x.com/2019/11/16/M0tMrj.md.png)](https://imgchr.com/i/M0tMrj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先初始化一条拟合直线$ y = w_{1}x+w_{2} $\n",
    "- 为了优化拟合效果，数据中的任意一点都想让直线离自己更近一些，那该如何移动这条直线呢？\n",
    "- 依据绝对值技巧，我们可以不断的更新直线的两个参数\n",
    "- 设定一个叫做学习率的值$ \\alpha $，用来调节参数优化的幅度"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![M0NnFx.md.png](https://s2.ax1x.com/2019/11/16/M0NnFx.md.png)](https://imgchr.com/i/M0NnFx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，对于绝对值技巧来说，\n",
    "- 我们要依据点与直线的上下关系，更改参数优化的符号；\n",
    "- 而且，参数优化的幅度是点与坐标轴的距离，而不是点与直线的距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 平方值技巧（Square Trick）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![M0aZPx.md.png](https://s2.ax1x.com/2019/11/16/M0aZPx.md.png)](https://imgchr.com/i/M0aZPx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在平方值技巧中，我们把点到直线的距离（$ q - q^{'} $）添加到了参数优化中，这样做还有一个好处就是：\n",
    "- 因为距离的存在，我们不需要再去判定点与直线的位置关系了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降（Gradient Descent）\n",
    "[![M0df9P.md.png](https://s2.ax1x.com/2019/11/16/M0df9P.md.png)](https://imgchr.com/i/M0df9P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沿着误差对参数梯度值的反向去更新参数，用学习率来控制参数优化的幅度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么如何评价线性回归中的误差呢？\n",
    "- 平均绝对误差（Mean Absolute Error，MAE）\n",
    "- 平均平方误差（Mean Squared Error，MSE）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-  平均绝对误差\n",
    "[![M0wHKO.md.png](https://s2.ax1x.com/2019/11/16/M0wHKO.md.png)](https://imgchr.com/i/M0wHKO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 平均平方误差\n",
    "[![M00Nz6.md.png](https://s2.ax1x.com/2019/11/16/M00Nz6.md.png)](https://imgchr.com/i/M00Nz6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里为什么要额外除以2呢？是为了方便求导之后没有任何常数，而且也不会改变最后的收敛结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实，上面提到的四种方法其实是两两等效的，即绝对值技巧等效于平均绝对误差的梯度下降，平方技巧等效于平均平方误差的梯度下降。下面我们来证明一下后者："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于任意一点(p,q)，拟合后的均方误差函数为$ Error = \\frac{1}{2}(q - q^{'})^2 $\n",
    "    - 其中，$ q^{'} = w_{1}p+w_{2} $\n",
    "- 应用梯度下降算法后，得到的权重更新为$ \\frac{\\partial }{\\partial w_{i}}Error = \\frac{\\partial Error}{\\partial q^{'}}\\cdot \\frac{\\partial q^{'}}{\\partial w_{i}} $\n",
    "    - 对于$ w_{1} $，更新为$w_{1}-( -(q - q^{'})p) $\n",
    "    - 对于$ w_{2} $，更新为$w_{2}- (-(q - q^{'}))$\n",
    "- 得到的优化值与用平方技巧是完全一致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前，我们已经掌握了优化线性回归的方法，但是，当数据量非常大时，我们还需要考虑一点：优化的速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提升梯度训练的速度\n",
    "- 全部参与训练 （Batch Gradient Descent）： 把所有的值计算，相加，然后更新参数\n",
    "- 随机取值训练（Stochastic Gradient Descent）：每次随机取一个点进行计算，更新参数，然后再取一个点\n",
    "- 分组参与训练（Mini-Batch 。。。）：把数据分成数据量差不多的组，每个组包含很少的数据，对每个组进行计算，相加，更新参数，然后计算下一个组\n",
    "- 随机分批次梯度训练 （Mini-Batch 。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
